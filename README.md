**Questions by David Crandall**
**Part 1: Pichu**
Chess has been called the “drosophila of artificial intelligence,” since it has long been a convenient yardstick by which to measure progress in AI (just as the fruit fly has been a relatively simple experimental “platform” for biology). Let’s consider Pichu, a somewhat simplified version of Chess that is popular among a certain community of midwestern bird enthusiasts.
The game is played by two players on a board consisting of a grid of 8 × 8 squares. Initially, each player has sixteen pieces: 8 Parakeets, 2 Robins, 2 Nighthawks, 2 Blue jays, 1 Quetzal, and 1 Kingfisher. The two players alternate turns, with White going first. 

Code written by **Goutham Srivatsav**

**Part 2: Tweet classification**
A classic application of Bayes Law is in document classification. Let’s examine one particular classification problem: estimating where a Twitter “tweet” was sent, based only on the content of the tweet itself. We’ll use a bag-of-words model, which means that we’ll represent a tweet in terms of just an unordered “bag” of words instead of modeling anything about its grammatical structure. In other words, a tweet can be modeled as simply a histogram over the words of the English language (or, more generally, all possible tokens that occur on Twitter). If, for example, there are 100,000 words in the English language, then a tweet can be represented as a 100,000-dimensional binary vector, where in each dimension there is a 1 if the word appears in the tweet and a zero otherwise. Of course, vectors will be very sparse (most entries are zero).

Code written by **Zoher Kachwala**
